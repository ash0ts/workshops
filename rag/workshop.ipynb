{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop: From Simple to Agentic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ‰ Free Cohere API key\n",
    "\n",
    "Before you run this notebook, head over to this [link to redeem a free Cohere API key](https://dashboard.cohere.com/billing?tab=payment&creditCode=WANDB-Y01D-JK8B).\n",
    "\n",
    "Alternatively if you have a Cohere API key feel free to proceed.\n",
    "\n",
    "To redeem your workshop credits:\n",
    "1. Make sure you are the admin of the account/team.\n",
    "2. Follow your unique link or use your code in the Cohere wallet to redeem the credits.\n",
    "[Link](https://dashboard.cohere.com/billing?tab=payment&creditCode=WANDB-Y01D-JK8B)\n",
    "\n",
    "Next head over to [Tavily](https://app.tavily.com/home) and sign up for a free account and get your API key.\n",
    "\n",
    "We will use [`uv`](https://docs.astral.sh/uv/getting-started/installation/) to install the workshop package and its dependencies.\n",
    "\n",
    "\n",
    "```bash\n",
    "!git clone https://github.com/parambharar/workshops.git\n",
    "!cd workshops/rag\n",
    "!pip install uv\n",
    "!uv pip install -e .\n",
    "```\n",
    "\n",
    "Create an `.env` file in the workshop/rag directory and add the API keys to it:\n",
    "\n",
    "```.env\n",
    "COHERE_API_KEY=\"YOUR_COHERE_API_KEY\"\n",
    "TAVILY_API_KEY=\"YOUR_TAVILY_API_KEY\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import wandb\n",
    "import weave\n",
    "from copy import deepcopy\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_contents_to_text, make_id, render_doc, printmd, chunk_simple, chunk_markdown, load_dataset, chunk_dataset\n",
    "from retrieval_metrics import RetrievalScorer\n",
    "from response_metrics import ResponseScorer\n",
    "from retriever import TfidfSearchEngine, BM25SearchEngine, DenseSearchEngine, Retriever, RetrieverWithReranker, HybridRetrieverWithReranker, VectorStoreSearchEngine\n",
    "from generation import SimpleResponseGenerator, QueryEnhancedResponseGenerator\n",
    "from pipeline import SimpleRAGPipeline, QueryEnhancedRAGPipeline\n",
    "from query_enhancer import QueryEnhancer\n",
    "from agent import WandbAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use W&B Artifacts to track and version data as the inputs and outputs of your W&B Runs. \n",
    "For example, a model training run might take in a dataset as input and produce a trained model as output. \n",
    "W&B Artifacts is a powerful object storage with rich UI functionalities.\n",
    "\n",
    "Below we are downloading an artifact named wandb_docs which will download 400 odd files in your `data/docs` directory. This is will act as our data source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api = wandb.Api()\n",
    "docs_root = wandb_api.artifact(\"parambharat/rag-workshop/documentation:latest\", type=\"dataset\").download(root=\"data/docs\")\n",
    "docs_file =  f\"{docs_root}/wandb_docs.jsonl\"\n",
    "with open(docs_file, \"r\") as f:\n",
    "    docs = f.readlines()\n",
    "docs = [json.loads(doc) for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weave_client = weave.init(\"rag-workshop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple RAG Pipeline\n",
    "\n",
    "First, we will learn about building a simple RAG pipeline. We will mainly focus on how to preprocess and chunk the data followed by building a simple retrieval engine without using any fancy \"Vector Index\". The idea is to show the inner working of a retrieval pipeline and make you understand the workflow from a user query to a generated response using an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chunks = []\n",
    "for doc in docs:\n",
    "    chunks = chunk_simple(doc[\"content\"], chunk_size=500)\n",
    "    doc_id = make_id(doc[\"content\"])\n",
    "    for chunk in chunks:\n",
    "        doc_chunk = deepcopy(doc)\n",
    "        doc_chunk[\"chunk\"] = chunk\n",
    "        doc_chunk[\"text\"] = convert_contents_to_text(chunk)\n",
    "        doc_chunk[\"chunk_id\"] = make_id(chunk)\n",
    "        doc_chunk[\"doc_id\"] = doc_id\n",
    "        document_chunks.append(doc_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_search_engine = await TfidfSearchEngine().fit(document_chunks)\n",
    "\n",
    "class TFIDFRetriever(Retriever):\n",
    "    pass\n",
    "\n",
    "tfidf_retriever = TFIDFRetriever(search_engine=tfidf_search_engine)\n",
    "# retrieved_docs = await tfidf_search_engine.search(query=\"What are Artifacts?\", top_k=5)\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs_data = [{\"document\": item[\"text\"]} for item in retrieved_docs]\n",
    "simple_response_generator = SimpleResponseGenerator()\n",
    "# response = await simple_response_generator.invoke(\n",
    "#     query=\"What are Artifacts?\", documents=docs_data\n",
    "# )\n",
    "# printmd(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFRAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "tfidf_rag_pipeline = TFIDFRAGPipeline(\n",
    "    retriever=tfidf_retriever,\n",
    "    generator=simple_response_generator\n",
    ")\n",
    "# response = await tfidf_rag_pipeline.invoke(query=\"What are Artifacts?\",)\n",
    "# printmd(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the RAG Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluating the Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/eval_dataset.jsonl\", \"r\") as f:\n",
    "#     eval_dataset = [json.loads(line) for line in f.readlines()]\n",
    "# eval_dataset = weave.Dataset(name=\"eval_dataset\", description=\"Evaluation dataset for RAG Pipeline\", rows=eval_dataset)\n",
    "# weave.publish(eval_dataset, name=\"eval_dataset\")\n",
    "# eval_dataset = weave.ref(\"weave:///parambharat/rag-workshop/object/eval_dataset:DkS8t0EnHiHQAmdmd9M9UzeJSyiOTNIr924v62abT4Q\").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = weave.ref(\"weave:///parambharat/rag-workshop/object/eval_dataset:9aTli8u1UJBYQD6aBWnYMUpokMjNUrXjQBspuAWBbYE\").get()\n",
    "\n",
    "print(\"Number of evaluation samples: \", len(eval_dataset.rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_evaluation = weave.Evaluation(\n",
    "    name=\"Retrieval_Evaluation\",\n",
    "    dataset=eval_dataset,\n",
    "    scorers=[RetrievalScorer(name=\"retrieval_scorer\", description=\"Retrieval metrics\")],\n",
    "    preprocess_model_input=lambda x: {\"query\": x[\"question\"], \"top_k\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=tfidf_retriever,\n",
    "    __weave={\"display_name\": \"TFIDF Retrieval\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluationg the Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "response_evaluation = weave.Evaluation(\n",
    "    name=\"Response_Evaluation\",\n",
    "    dataset=eval_dataset,\n",
    "    scorers=[ResponseScorer(name=\"response_scorer\", description=\"Response metrics\")],\n",
    "    preprocess_model_input=lambda x: {\"query\": x[\"question\"]},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_response_scores = await response_evaluation.evaluate(\n",
    "    model=tfidf_rag_pipeline,\n",
    "    __weave={\"display_name\": \"TFIDF RAG Pipeline\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_search_engine = await BM25SearchEngine().fit(document_chunks)\n",
    "\n",
    "class BM25Retriever(Retriever):\n",
    "    pass\n",
    "\n",
    "bm25_retriever = BM25Retriever(search_engine=bm25_search_engine)\n",
    "\n",
    "# retrieved_docs = await bm25_retriever.invoke(query=\"What are Artifacts?\", top_k=5)\n",
    "\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=bm25_retriever,\n",
    "    __weave={\"display_name\": \"BM25 Retrieval\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BM25RAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "\n",
    "bm25_rag_pipeline = BM25RAGPipeline(\n",
    "    retriever=bm25_retriever,\n",
    "    generator=simple_response_generator\n",
    ")\n",
    "\n",
    "# response = await bm25_rag_pipeline.invoke(query=\"What are Artifacts?\",)\n",
    "\n",
    "# printmd(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_scores = await response_evaluation.evaluate(\n",
    "    model=bm25_rag_pipeline,\n",
    "    __weave={\"display_name\": \"BM25 RAG Pipeline\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_search_engine = DenseSearchEngine()\n",
    "dense_search_engine = await dense_search_engine.fit(document_chunks)\n",
    "\n",
    "class DenseRetriever(Retriever):\n",
    "    pass\n",
    "\n",
    "dense_retriever = DenseRetriever(search_engine=dense_search_engine)\n",
    "# retrieved_docs = await dense_retriever.invoke(query=\"What are Artifacts?\", top_k=5)\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=dense_retriever,\n",
    "    __weave={\"display_name\": \"Dense Retrieval\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseRAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "\n",
    "dense_rag_pipeline = DenseRAGPipeline(\n",
    "    retriever=dense_retriever,\n",
    "    generator=simple_response_generator\n",
    ")\n",
    "\n",
    "# response = await dense_rag_pipeline.invoke(query=\"What are Artifacts?\",)\n",
    "\n",
    "# printmd(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_scores = await response_evaluation.evaluate(\n",
    "    model=dense_rag_pipeline,\n",
    "    __weave={\"display_name\": \"Dense RAG Pipeline\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DenseRerankedRetriever(RetrieverWithReranker):\n",
    "    pass\n",
    "\n",
    "dense_reranked_retriever = DenseRerankedRetriever(search_engine=dense_search_engine,)\n",
    "\n",
    "# retrieved_docs = await dense_reranked_retriever.invoke(query=\"What are Artifacts?\", top_k=10, top_n=5)\n",
    "\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=dense_reranked_retriever,\n",
    "    __weave={\"display_name\": \"Dense Reranked Retrieval\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseRerankedRAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "\n",
    "dense_reranked_rag_pipeline = DenseRerankedRAGPipeline(\n",
    "    retriever=dense_reranked_retriever,\n",
    "    generator=simple_response_generator\n",
    ")\n",
    "\n",
    "# response = await dense_reranked_rag_pipeline.invoke(query=\"What are Artifacts?\",)\n",
    "\n",
    "# printmd(response[\"answer\"])\n",
    "response_scores = await response_evaluation.evaluate(\n",
    "    model=dense_reranked_rag_pipeline,\n",
    "    __weave={\"display_name\": \"Dense Reranked RAG Pipeline\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retriever = HybridRetrieverWithReranker(\n",
    "    sparse_search_engine=tfidf_search_engine,\n",
    "    dense_search_engine=dense_search_engine\n",
    ")\n",
    "\n",
    "# retrieved_docs = await hybrid_retriever.invoke(query=\"What are Artifacts?\", top_k=10, top_n=5)\n",
    "\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=hybrid_retriever,\n",
    "    __weave={\"display_name\": \"Hybrid Retrieval\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "\n",
    "hybrid_rag_pipeline = HybridRAGPipeline(\n",
    "    retriever=hybrid_retriever,\n",
    "    generator=simple_response_generator\n",
    ")\n",
    "\n",
    "# response = await hybrid_rag_pipeline.invoke(query=\"What are Artifacts?\",)\n",
    "\n",
    "# printmd(response[\"answer\"])\n",
    "hybrid_response_scores = await response_evaluation.evaluate(\n",
    "    model=hybrid_rag_pipeline,\n",
    "    __weave={\"display_name\": \"Hybrid RAG Pipeline\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_docs = chunk_markdown(docs[0][\"content\"], chunk_size=500)\n",
    "chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chunks = []\n",
    "for doc in docs:\n",
    "    chunks = chunk_markdown(doc[\"content\"], chunk_size=500)\n",
    "    doc_id = make_id(doc[\"content\"])\n",
    "    for chunk in chunks:\n",
    "        doc_chunk = deepcopy(doc)\n",
    "        doc_chunk[\"chunk\"] = chunk\n",
    "        doc_chunk[\"text\"] = convert_contents_to_text(chunk)\n",
    "        doc_chunk[\"chunk_id\"] = make_id(chunk)\n",
    "        doc_chunk[\"doc_id\"] = doc_id\n",
    "        document_chunks.append(doc_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_search_engine = await BM25SearchEngine().fit(document_chunks)\n",
    "dense_search_engine = await DenseSearchEngine().fit(document_chunks)\n",
    "hybrid_retriever = HybridRetrieverWithReranker(\n",
    "    sparse_search_engine=bm25_search_engine,\n",
    "    dense_search_engine=dense_search_engine\n",
    ")\n",
    "\n",
    "# retrieved_docs = await hybrid_retriever.invoke(query=\"What are Artifacts?\", top_k=10, top_n=5)\n",
    "\n",
    "# for doc in retrieved_docs:\n",
    "#     render_doc(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_evaluation = weave.Evaluation(\n",
    "    name=\"Retrieval_Evaluation\",\n",
    "    dataset=eval_dataset,\n",
    "    scorers=[RetrievalScorer(name=\"retrieval_scorer\", description=\"Retrieval metrics\")],\n",
    "    preprocess_model_input=lambda x: {\"query\": x[\"question\"], \"top_k\": 10, \"top_n\": 5},\n",
    ")\n",
    "hybrid_retrieval_scores = await retrieval_evaluation.evaluate(\n",
    "    model=hybrid_retriever,\n",
    "    __weave={\"display_name\": \"Hybrid Retrieval With Structured Chunking\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HybridRAGPipeline(SimpleRAGPipeline):\n",
    "    pass\n",
    "\n",
    "hybrid_rag_pipeline = HybridRAGPipeline(\n",
    "    retriever=hybrid_retriever,\n",
    "    generator=simple_response_generator)\n",
    "\n",
    "# response = await hybrid_rag_pipeline.invoke(query=\"What are Artifacts?\",)\n",
    "\n",
    "# printmd(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_response_scores = await response_evaluation.evaluate(\n",
    "    model=hybrid_rag_pipeline,\n",
    "    __weave={\"display_name\": \"Hybrid RAG Pipeline With Structured Chunking\"}\n",
    ")\n",
    "hybrid_response_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More data, vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_dataset = load_dataset(docs_root)\n",
    "# chunked_dataset = chunk_dataset(full_dataset, chunk_size=500)\n",
    "# vectorstore_search_engine = VectorStoreSearchEngine()\n",
    "# vectorstore_search_engine = await vectorstore_search_engine.fit(chunked_dataset)\n",
    "vectorstore_search_engine = VectorStoreSearchEngine()\n",
    "vectorstore_search_engine = await vectorstore_search_engine.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = await vectorstore_search_engine.search(\n",
    "#     query=\"What are Artifacts?\",\n",
    "#     top_k=5,\n",
    "#     filters=\"file_type in ('notebook', 'markdown')\")\n",
    "# for doc in results:\n",
    "#     render_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStoreRetriever(RetrieverWithReranker):\n",
    "    pass\n",
    "\n",
    "vectorstore_retriever = VectorStoreRetriever(search_engine=vectorstore_search_engine)\n",
    "\n",
    "# results = await vectorstore_retriever.invoke(query=\"What are Artifacts?\", top_k=10, top_n=5, filters=\"file_type in ('notebook', 'markdown')\")\n",
    "# for doc in results:\n",
    "#     render_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_enhancer = QueryEnhancer()\n",
    "results = await query_enhancer.invoke(\"What are W&B Artifacts?\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_enhanced_rag_pipeline = QueryEnhancedRAGPipeline(\n",
    "    query_enhancer=query_enhancer,\n",
    "    retriever=vectorstore_retriever,\n",
    "    response_generator=QueryEnhancedResponseGenerator()\n",
    ")\n",
    "response = await query_enhanced_rag_pipeline.invoke(\"What are Artifacts?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_enhanced_response_scores = await response_evaluation.evaluate(\n",
    "    model=query_enhanced_rag_pipeline,\n",
    "    __weave={\"display_name\": \"Query Enhanced RAG Pipeline\"}\n",
    ")\n",
    "query_enhanced_response_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = WandbAgent()\n",
    "\n",
    "query = \"Are there any notebooks related to artifacts?\"\n",
    "answer = await agent.invoke(query)\n",
    "printmd(answer[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Where can I find the output of a run?\"\n",
    "answer = await agent.invoke(query)\n",
    "printmd(answer[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who are the authors of the sentence BERT paper?\"\n",
    "answer = await agent.invoke(query)\n",
    "printmd(answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Explain what is a W&B Run and how do I view a specific run\"\n",
    "answer = await agent.invoke(query)\n",
    "printmd(answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
